{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN30UPxFZ3c7lh9AZ0MZffM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGFvR3zAXoJN",
        "outputId": "5cbed3aa-0243-478b-9ea0-a6044b4bb944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing compatible PyTorch versions...\n",
            "Mounted at /content/drive\n",
            "Running in Google Colab\n",
            "Using device: cpu\n",
            "=== Gradient Inversion Attack Demo ===\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 82.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretraining model...\n",
            "Epoch 1, Batch 50: Loss=9.397, Acc=16.91%\n",
            "Epoch 1, Batch 100: Loss=2.145, Acc=22.95%\n",
            "Epoch 1, Batch 150: Loss=1.949, Acc=26.01%\n",
            "Epoch 1, Batch 200: Loss=2.032, Acc=27.49%\n",
            "Epoch 1, Batch 250: Loss=2.086, Acc=28.49%\n",
            "Epoch 1, Batch 300: Loss=2.320, Acc=29.28%\n",
            "Epoch 1, Batch 350: Loss=2.134, Acc=29.72%\n",
            "Epoch 2, Batch 50: Loss=2.134, Acc=34.44%\n",
            "Epoch 2, Batch 100: Loss=1.849, Acc=36.55%\n",
            "Epoch 2, Batch 150: Loss=1.875, Acc=36.75%\n",
            "Epoch 2, Batch 200: Loss=2.565, Acc=35.84%\n",
            "Epoch 2, Batch 250: Loss=1.966, Acc=36.28%\n",
            "Epoch 2, Batch 300: Loss=1.923, Acc=36.53%\n",
            "Epoch 2, Batch 350: Loss=1.924, Acc=36.95%\n",
            "Epoch 3, Batch 50: Loss=2.023, Acc=38.88%\n",
            "Epoch 3, Batch 100: Loss=1.853, Acc=40.02%\n",
            "Epoch 3, Batch 150: Loss=1.685, Acc=41.07%\n",
            "Epoch 3, Batch 200: Loss=1.753, Acc=41.15%\n",
            "Epoch 3, Batch 250: Loss=1.987, Acc=41.02%\n",
            "Epoch 3, Batch 300: Loss=1.851, Acc=41.28%\n",
            "Epoch 3, Batch 350: Loss=1.739, Acc=41.55%\n",
            "Epoch 4, Batch 50: Loss=1.681, Acc=45.44%\n",
            "Epoch 4, Batch 100: Loss=1.735, Acc=45.80%\n",
            "Epoch 4, Batch 150: Loss=1.535, Acc=46.48%\n",
            "Epoch 4, Batch 200: Loss=1.626, Acc=46.62%\n",
            "Epoch 4, Batch 250: Loss=1.637, Acc=46.67%\n",
            "Epoch 4, Batch 300: Loss=1.539, Acc=47.13%\n",
            "Epoch 4, Batch 350: Loss=1.497, Acc=47.49%\n",
            "Epoch 5, Batch 50: Loss=1.422, Acc=51.34%\n",
            "Epoch 5, Batch 100: Loss=1.381, Acc=51.71%\n",
            "Epoch 5, Batch 150: Loss=1.454, Acc=51.36%\n",
            "Epoch 5, Batch 200: Loss=1.493, Acc=51.21%\n",
            "Epoch 5, Batch 250: Loss=1.535, Acc=51.04%\n",
            "Epoch 5, Batch 300: Loss=1.561, Acc=50.87%\n",
            "Epoch 5, Batch 350: Loss=1.569, Acc=50.77%\n",
            "Enter number of images to attack (1-5): 1\n",
            "\n",
            "=== Attacking Image 1/1 ===\n",
            "True class: bird\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reconstructing:   0%|          | 1/1000 [00:00<04:40,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 0: Grad Loss=558.348938, Total Loss=558.349487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reconstructing:  10%|█         | 101/1000 [00:23<03:31,  4.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 100: Grad Loss=1.876300, Total Loss=1.882051\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reconstructing:  20%|██        | 201/1000 [00:50<03:39,  3.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 200: Grad Loss=1.684151, Total Loss=1.689986\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reconstructing:  30%|███       | 301/1000 [01:15<03:54,  2.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 300: Grad Loss=0.648379, Total Loss=0.654390\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reconstructing:  50%|█████     | 501/1000 [02:07<01:56,  4.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 500: Grad Loss=1.118638, Total Loss=1.125685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reconstructing:  70%|███████   | 701/1000 [02:59<01:11,  4.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iter 700: Grad Loss=0.914425, Total Loss=0.921304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reconstructing: 100%|██████████| 1000/1000 [04:16<00:00,  3.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: bird\n",
            "PSNR: 7.00 dB, SSIM: 0.3203\n",
            "\n",
            "Results saved to: /content/drive/MyDrive/gradinversion_results_20250601_121307\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "GradInversion Attack: Reconstructing Training Data from Gradients\n",
        "=================================================================\n",
        "This module demonstrates how neural network gradients can leak private training data.\n",
        "It implements optimization-based reconstruction techniques to recover images from gradients.\n",
        "\n",
        "Key Components:\n",
        "- Gradient-friendly CNN architecture using smooth activations\n",
        "- Multi-objective optimization for image reconstruction\n",
        "- Evaluation metrics (PSNR, SSIM, MSE)\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "import traceback\n",
        "\n",
        "# Check environment and setup\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    print(\"Installing compatible PyTorch versions...\")\n",
        "    os.system(\"pip install --upgrade torch torchvision\")\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"Running in Google Colab\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "torch.manual_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "\n",
        "# Device configuration\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "\n",
        "# Constants\n",
        "CIFAR10_CLASSES = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                   'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "IMAGE_SIZE = 32\n",
        "NUM_CHANNELS = 3\n",
        "NUM_CLASSES = 10\n",
        "\n",
        "\n",
        "class SmoothCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN architecture optimized for gradient inversion.\n",
        "    Uses smooth activations (sigmoid) instead of ReLU to preserve gradient information.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1: 3 -> 64 channels\n",
        "            nn.Conv2d(NUM_CHANNELS, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Sigmoid(),\n",
        "\n",
        "            # Block 2: 64 -> 128 channels with pooling\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.AvgPool2d(2),  # Preserves more info than MaxPool\n",
        "\n",
        "            # Block 3: 128 -> 128 channels\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.classifier = nn.Linear(128 * 16 * 16, NUM_CLASSES)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(-1, 128 * 16 * 16)\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "class FeatureExtractor(nn.Module):\n",
        "    \"\"\"Simple feature extractor for perceptual loss computation.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(NUM_CHANNELS, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.AvgPool2d(2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='sigmoid')\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.shape[2] != IMAGE_SIZE:\n",
        "            x = F.interpolate(x, size=(IMAGE_SIZE, IMAGE_SIZE), mode='bilinear', align_corners=True)\n",
        "        return self.features(x)\n",
        "\n",
        "\n",
        "class GradientInverter:\n",
        "    \"\"\"Reconstructs training data from gradients using optimization techniques.\"\"\"\n",
        "\n",
        "    def __init__(self, model, feature_extractor, device=DEVICE):\n",
        "        self.model = model\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.device = device\n",
        "        self.save_iterations = [0, 1, 2, 5, 10, 20, 50, 100, 200, 300, 500, 700, 999]\n",
        "\n",
        "    def _initialize_dummy_data(self, target_gradients, batch_size=1):\n",
        "        \"\"\"Initialize dummy data using gradient-guided patterns.\"\"\"\n",
        "        dummy_data = torch.zeros((batch_size, NUM_CHANNELS, IMAGE_SIZE, IMAGE_SIZE), device=self.device)\n",
        "\n",
        "        # Use first layer gradients to guide channel importance\n",
        "        first_layer_grad = target_gradients[0]\n",
        "        channel_importance = F.softmax(torch.sum(torch.abs(first_layer_grad), dim=[0, 2, 3]), dim=0)\n",
        "\n",
        "        # Create structured initialization for each image\n",
        "        for b in range(batch_size):\n",
        "            for c in range(NUM_CHANNELS):\n",
        "                # Gaussian-like pattern with channel weighting\n",
        "                center_x = IMAGE_SIZE // 2 + 5 * (random.random() - 0.5)\n",
        "                center_y = IMAGE_SIZE // 2 + 5 * (random.random() - 0.5)\n",
        "                sigma = 10 + 5 * random.random()\n",
        "\n",
        "                for i in range(IMAGE_SIZE):\n",
        "                    for j in range(IMAGE_SIZE):\n",
        "                        dist = np.sqrt((i - center_x)**2 + (j - center_y)**2)\n",
        "                        val = 0.5 * np.exp(-dist/sigma) + 0.1 * random.random()\n",
        "                        dummy_data[b, c, i, j] = val * (0.5 + channel_importance[c].item())\n",
        "\n",
        "        # Initialize labels using final layer gradients\n",
        "        last_layer_grad = target_gradients[-2]\n",
        "        dummy_label = F.softmax(-torch.sum(last_layer_grad, dim=1) * 5, dim=0).unsqueeze(0)\n",
        "\n",
        "        return dummy_data.clamp_(0, 1).requires_grad_(True), dummy_label.requires_grad_(True)\n",
        "\n",
        "    def _compute_regularization_weights(self, iteration, max_iterations):\n",
        "        \"\"\"Compute annealed regularization weights.\"\"\"\n",
        "        progress = iteration / max_iterations\n",
        "        return {\n",
        "            'gradient': 1.0,\n",
        "            'tv': 0.01 * (1 - 0.9 * progress),\n",
        "            'l2': 0.0001 * (1 - 0.9 * progress),\n",
        "            'perceptual': 0.05 * min(1.0, 2 * progress),\n",
        "            'smoothness': 0.02 * min(1.0, 3 * progress),\n",
        "            'bn_stats': 0.01 * min(1.0, 2 * progress),\n",
        "        }\n",
        "\n",
        "    def _gradient_matching_loss(self, dummy_gradients, target_gradients):\n",
        "        \"\"\"Compute weighted gradient matching loss.\"\"\"\n",
        "        loss = 0\n",
        "        for i, (dummy_grad, target_grad) in enumerate(zip(dummy_gradients, target_gradients)):\n",
        "            # Higher weight for early layers\n",
        "            layer_weight = 10.0 if i < 2 else 5.0 if i < 4 else 1.0\n",
        "            layer_loss = ((dummy_grad - target_grad) ** 2).sum() / dummy_grad.numel()\n",
        "            loss += layer_weight * layer_loss\n",
        "        return loss\n",
        "\n",
        "    def _total_variation_loss(self, x):\n",
        "        \"\"\"Compute total variation loss for image smoothness.\"\"\"\n",
        "        tv_h = torch.abs(x[:, :, :-1, :] - x[:, :, 1:, :]).sum()\n",
        "        tv_w = torch.abs(x[:, :, :, :-1] - x[:, :, :, 1:]).sum()\n",
        "        return (tv_h + tv_w) / x.numel()\n",
        "\n",
        "    def _smoothness_loss(self, x):\n",
        "        \"\"\"Encourage local smoothness in the image.\"\"\"\n",
        "        blurred = F.avg_pool2d(F.pad(x, (1, 1, 1, 1), mode='reflect'), 3, stride=1)\n",
        "        return F.mse_loss(blurred, x)\n",
        "\n",
        "    def reconstruct(self, target_gradients, original_image=None, num_iterations=1000):\n",
        "        \"\"\"\n",
        "        Reconstruct image from gradients.\n",
        "\n",
        "        Args:\n",
        "            target_gradients: List of gradient tensors from the model\n",
        "            original_image: Ground truth image (optional, for evaluation)\n",
        "            num_iterations: Number of optimization iterations\n",
        "\n",
        "        Returns:\n",
        "            Reconstructed image and predicted label\n",
        "        \"\"\"\n",
        "        # Initialize reconstruction\n",
        "        dummy_data, dummy_label = self._initialize_dummy_data(target_gradients)\n",
        "\n",
        "        # Setup optimizer\n",
        "        optimizer = torch.optim.Adam([\n",
        "            {'params': dummy_data, 'lr': 0.1},\n",
        "            {'params': dummy_label, 'lr': 0.01}\n",
        "        ])\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_iterations, eta_min=0.001)\n",
        "\n",
        "        # Loss function\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # Store batch norm statistics\n",
        "        bn_stats = self._extract_bn_stats()\n",
        "\n",
        "        # Optimization loop\n",
        "        history = {'images': [], 'iterations': [], 'losses': []}\n",
        "\n",
        "        for iteration in tqdm(range(num_iterations), desc=\"Reconstructing\"):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Get regularization weights\n",
        "            weights = self._compute_regularization_weights(iteration, num_iterations)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = self.model(dummy_data)\n",
        "            loss = criterion(outputs, F.softmax(dummy_label, dim=1))\n",
        "\n",
        "            # Compute gradients\n",
        "            dummy_gradients = []\n",
        "            for param in self.model.parameters():\n",
        "                grad = torch.autograd.grad(loss, param, create_graph=True, retain_graph=True)[0]\n",
        "                dummy_gradients.append(grad)\n",
        "\n",
        "            # Compute losses\n",
        "            grad_loss = self._gradient_matching_loss(dummy_gradients, target_gradients)\n",
        "            tv_loss = self._total_variation_loss(dummy_data) if weights['tv'] > 0 else 0\n",
        "            l2_loss = torch.norm(dummy_data) / dummy_data.numel()\n",
        "            smooth_loss = self._smoothness_loss(dummy_data) if weights['smoothness'] > 0 else 0\n",
        "\n",
        "            # Perceptual loss\n",
        "            perceptual_loss = 0\n",
        "            if weights['perceptual'] > 0 and iteration > 50:\n",
        "                dummy_features = self.feature_extractor(dummy_data)\n",
        "                if original_image is not None:\n",
        "                    orig_features = self.feature_extractor(original_image)\n",
        "                    perceptual_loss = F.mse_loss(dummy_features, orig_features)\n",
        "                else:\n",
        "                    perceptual_loss = -torch.mean(dummy_features)\n",
        "\n",
        "            # Total loss\n",
        "            total_loss = (\n",
        "                weights['gradient'] * grad_loss +\n",
        "                weights['tv'] * tv_loss +\n",
        "                weights['l2'] * l2_loss +\n",
        "                weights['perceptual'] * perceptual_loss +\n",
        "                weights['smoothness'] * smooth_loss\n",
        "            )\n",
        "\n",
        "            # Optimize\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            # Clamp values\n",
        "            with torch.no_grad():\n",
        "                dummy_data.clamp_(0, 1)\n",
        "\n",
        "                # Periodic sharpening\n",
        "                if iteration > 0 and iteration % 100 == 0 and iteration >= 300:\n",
        "                    blurred = F.avg_pool2d(F.pad(dummy_data, (1, 1, 1, 1), mode='reflect'), 3, stride=1)\n",
        "                    dummy_data += 0.3 * (dummy_data - blurred)\n",
        "                    dummy_data.clamp_(0, 1)\n",
        "\n",
        "            # Save progress\n",
        "            if iteration in self.save_iterations:\n",
        "                history['images'].append(dummy_data.clone().detach().cpu())\n",
        "                history['iterations'].append(iteration)\n",
        "                history['losses'].append(total_loss.item())\n",
        "\n",
        "                if iteration % 100 == 0:\n",
        "                    print(f\"Iter {iteration}: Grad Loss={grad_loss:.6f}, Total Loss={total_loss:.6f}\")\n",
        "\n",
        "        return dummy_data.detach(), F.softmax(dummy_label, dim=1).detach(), history\n",
        "\n",
        "    def _extract_bn_stats(self):\n",
        "        \"\"\"Extract batch normalization statistics.\"\"\"\n",
        "        stats = {'mean': [], 'var': []}\n",
        "        for m in self.model.modules():\n",
        "            if isinstance(m, nn.BatchNorm2d):\n",
        "                stats['mean'].append(m.running_mean.clone())\n",
        "                stats['var'].append(m.running_var.clone())\n",
        "        return stats\n",
        "\n",
        "\n",
        "class AttackEvaluator:\n",
        "    \"\"\"Evaluates reconstruction quality using various metrics.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_metrics(original, reconstructed):\n",
        "        \"\"\"Compute reconstruction quality metrics.\"\"\"\n",
        "        mse = F.mse_loss(original, reconstructed).item()\n",
        "        psnr = 10 * np.log10(1.0 / max(mse, 1e-10))\n",
        "        ssim = AttackEvaluator._compute_ssim(original, reconstructed)\n",
        "\n",
        "        return {\n",
        "            'mse': mse,\n",
        "            'psnr': psnr,\n",
        "            'ssim': ssim\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def _compute_ssim(img1, img2):\n",
        "        \"\"\"Compute Structural Similarity Index.\"\"\"\n",
        "        C1, C2 = 0.01**2, 0.03**2\n",
        "\n",
        "        # Convert to grayscale\n",
        "        img1_gray = 0.299 * img1[:, 0] + 0.587 * img1[:, 1] + 0.114 * img1[:, 2]\n",
        "        img2_gray = 0.299 * img2[:, 0] + 0.587 * img2[:, 1] + 0.114 * img2[:, 2]\n",
        "\n",
        "        # Compute SSIM\n",
        "        mu1 = F.avg_pool2d(img1_gray, kernel_size=11, stride=1, padding=5)\n",
        "        mu2 = F.avg_pool2d(img2_gray, kernel_size=11, stride=1, padding=5)\n",
        "\n",
        "        mu1_sq = mu1**2\n",
        "        mu2_sq = mu2**2\n",
        "        mu1_mu2 = mu1 * mu2\n",
        "\n",
        "        sigma1_sq = F.avg_pool2d(img1_gray**2, kernel_size=11, stride=1, padding=5) - mu1_sq\n",
        "        sigma2_sq = F.avg_pool2d(img2_gray**2, kernel_size=11, stride=1, padding=5) - mu2_sq\n",
        "        sigma12 = F.avg_pool2d(img1_gray * img2_gray, kernel_size=11, stride=1, padding=5) - mu1_mu2\n",
        "\n",
        "        ssim_map = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
        "        return torch.mean(ssim_map).item()\n",
        "\n",
        "\n",
        "class ExperimentRunner:\n",
        "    \"\"\"Manages and runs gradient inversion experiments.\"\"\"\n",
        "\n",
        "    def __init__(self, results_dir=None):\n",
        "        self.results_dir = results_dir or self._create_results_dir()\n",
        "        self.model = SmoothCNN().to(DEVICE)\n",
        "        self.feature_extractor = FeatureExtractor().to(DEVICE)\n",
        "        self.inverter = GradientInverter(self.model, self.feature_extractor)\n",
        "        self.evaluator = AttackEvaluator()\n",
        "\n",
        "    def _create_results_dir(self):\n",
        "        \"\"\"Create timestamped results directory.\"\"\"\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        base_dir = \"/content/drive/MyDrive\" if IN_COLAB else \".\"\n",
        "        results_dir = f\"{base_dir}/gradinversion_results_{timestamp}\"\n",
        "        os.makedirs(results_dir, exist_ok=True)\n",
        "        return results_dir\n",
        "\n",
        "    def pretrain_model(self, dataloader, epochs=5):\n",
        "        \"\"\"Pretrain model on dataset.\"\"\"\n",
        "        print(\"Pretraining model...\")\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
        "\n",
        "        self.model.train()\n",
        "        for epoch in range(epochs):\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for i, (inputs, labels) in enumerate(dataloader):\n",
        "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = outputs.max(1)\n",
        "                total += labels.size(0)\n",
        "                correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "                if i % 50 == 49:\n",
        "                    print(f'Epoch {epoch+1}, Batch {i+1}: Loss={running_loss/50:.3f}, Acc={100.*correct/total:.2f}%')\n",
        "                    running_loss = 0.0\n",
        "\n",
        "    def extract_gradients(self, image, label):\n",
        "        \"\"\"Extract gradients for given image and label.\"\"\"\n",
        "        self.model.eval()\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        outputs = self.model(image)\n",
        "        loss = criterion(outputs, label)\n",
        "\n",
        "        gradients = []\n",
        "        for param in self.model.parameters():\n",
        "            grad = torch.autograd.grad(loss, param, retain_graph=True)[0]\n",
        "            gradients.append(grad)\n",
        "\n",
        "        return gradients\n",
        "\n",
        "    def run_attack(self, test_images, test_labels):\n",
        "        \"\"\"Run gradient inversion attack on test images.\"\"\"\n",
        "        results = []\n",
        "\n",
        "        for i, (image, label) in enumerate(zip(test_images, test_labels)):\n",
        "            print(f\"\\n=== Attacking Image {i+1}/{len(test_images)} ===\")\n",
        "            true_class = CIFAR10_CLASSES[label.item()]\n",
        "            print(f\"True class: {true_class}\")\n",
        "\n",
        "            # Extract gradients\n",
        "            gradients = self.extract_gradients(image.unsqueeze(0), label.unsqueeze(0))\n",
        "\n",
        "            # Reconstruct image\n",
        "            reconstructed, pred_label, history = self.inverter.reconstruct(\n",
        "                gradients, original_image=image.unsqueeze(0)\n",
        "            )\n",
        "\n",
        "            # Evaluate\n",
        "            pred_class = CIFAR10_CLASSES[pred_label.argmax().item()]\n",
        "            metrics = self.evaluator.compute_metrics(image.unsqueeze(0), reconstructed)\n",
        "\n",
        "            print(f\"Predicted class: {pred_class}\")\n",
        "            print(f\"PSNR: {metrics['psnr']:.2f} dB, SSIM: {metrics['ssim']:.4f}\")\n",
        "\n",
        "            # Save results\n",
        "            self._save_results(i, image, reconstructed, history, true_class, pred_class, metrics)\n",
        "\n",
        "            results.append({\n",
        "                'true_class': true_class,\n",
        "                'pred_class': pred_class,\n",
        "                'metrics': metrics\n",
        "            })\n",
        "\n",
        "        self._save_summary(results)\n",
        "        return results\n",
        "\n",
        "    def _save_results(self, idx, original, reconstructed, history, true_class, pred_class, metrics):\n",
        "        \"\"\"Save attack results and visualizations.\"\"\"\n",
        "        # Save comparison\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "\n",
        "        axes[0].imshow(original.cpu().permute(1, 2, 0).numpy())\n",
        "        axes[0].set_title(f\"Original\\n{true_class}\")\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        axes[1].imshow(reconstructed[0].cpu().permute(1, 2, 0).numpy())\n",
        "        axes[1].set_title(f\"Reconstructed\\n{pred_class}\")\n",
        "        axes[1].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.results_dir}/comparison_{idx+1}.png\", dpi=150)\n",
        "        plt.close()\n",
        "\n",
        "        # Save reconstruction progress\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for i, (img, iter_num) in enumerate(zip(history['images'][:8], history['iterations'][:8])):\n",
        "            axes[i].imshow(img[0].permute(1, 2, 0).numpy())\n",
        "            axes[i].set_title(f\"Iter {iter_num}\")\n",
        "            axes[i].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"{self.results_dir}/progress_{idx+1}.png\", dpi=150)\n",
        "        plt.close()\n",
        "\n",
        "    def _save_summary(self, results):\n",
        "        \"\"\"Save experiment summary.\"\"\"\n",
        "        with open(f\"{self.results_dir}/summary.txt\", \"w\") as f:\n",
        "            f.write(\"GRADIENT INVERSION ATTACK RESULTS\\n\")\n",
        "            f.write(\"=\" * 50 + \"\\n\\n\")\n",
        "\n",
        "            # Statistics\n",
        "            correct = sum(1 for r in results if r['true_class'] == r['pred_class'])\n",
        "            avg_psnr = np.mean([r['metrics']['psnr'] for r in results])\n",
        "            avg_ssim = np.mean([r['metrics']['ssim'] for r in results])\n",
        "\n",
        "            f.write(f\"Total images: {len(results)}\\n\")\n",
        "            f.write(f\"Correct predictions: {correct}/{len(results)} ({100*correct/len(results):.1f}%)\\n\")\n",
        "            f.write(f\"Average PSNR: {avg_psnr:.2f} dB\\n\")\n",
        "            f.write(f\"Average SSIM: {avg_ssim:.4f}\\n\\n\")\n",
        "\n",
        "            # Detailed results\n",
        "            f.write(\"Image | True Class | Pred Class | PSNR  | SSIM\\n\")\n",
        "            f.write(\"-\" * 50 + \"\\n\")\n",
        "            for i, r in enumerate(results):\n",
        "                f.write(f\"{i+1:5d} | {r['true_class']:10s} | {r['pred_class']:10s} | \"\n",
        "                       f\"{r['metrics']['psnr']:5.2f} | {r['metrics']['ssim']:.4f}\\n\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main entry point for gradient inversion attack demonstration.\"\"\"\n",
        "    print(\"=== Gradient Inversion Attack Demo ===\\n\")\n",
        "\n",
        "    # Load CIFAR-10 dataset\n",
        "    transform = transforms.ToTensor()\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=True, num_workers=2)\n",
        "\n",
        "    # Initialize experiment\n",
        "    runner = ExperimentRunner()\n",
        "\n",
        "    # Pretrain model\n",
        "    runner.pretrain_model(trainloader)\n",
        "\n",
        "    # Select test images\n",
        "    num_images = int(input(\"Enter number of images to attack (1-5): \"))\n",
        "    num_images = max(1, min(5, num_images))\n",
        "\n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "    for i, (img, label) in enumerate(testloader):\n",
        "        if i >= num_images:\n",
        "            break\n",
        "        test_images.append(img[0].to(DEVICE))\n",
        "        test_labels.append(label[0].to(DEVICE))\n",
        "\n",
        "    # Run attack\n",
        "    results = runner.run_attack(test_images, test_labels)\n",
        "\n",
        "    print(f\"\\nResults saved to: {runner.results_dir}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        main()\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "        traceback.print_exc()"
      ]
    }
  ]
}